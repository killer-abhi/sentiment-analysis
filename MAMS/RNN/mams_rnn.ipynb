{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, agree, about, arafat, ,, i, mean, ,, shit,...</td>\n",
       "      <td>[LS, VBP, IN, NN, ,, FW, NN, ,, NN, ,, PRP, RB...</td>\n",
       "      <td>[2, 0, 4, 2, 7, 7, 2, 7, 2, 2, 13, 13, 2, 13, ...</td>\n",
       "      <td>[nsubj, root, case, nmod, punct, nsubj, parata...</td>\n",
       "      <td>[{'term': ['jimmy', 'carter'], 'from': 15, 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[musicmonday, britney, spears, -, lucky, do, y...</td>\n",
       "      <td>[NN, NN, NNS, :, JJ, VBP, PRP, VB, DT, NN, ,, ...</td>\n",
       "      <td>[3, 3, 0, 3, 3, 8, 8, 3, 10, 8, 8, 8, 8, 15, 3...</td>\n",
       "      <td>[amod, compound, root, punct, dep, aux, nsubj,...</td>\n",
       "      <td>[{'term': ['britney', 'spears'], 'from': 1, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wtf, ,, hilary, swank, is, coming, to, my, sc...</td>\n",
       "      <td>[NN, ,, JJ, NN, VBZ, VBG, TO, PRP$, NN, NN, ,,...</td>\n",
       "      <td>[6, 6, 4, 6, 6, 0, 9, 9, 6, 6, 6, 14, 14, 6, 1...</td>\n",
       "      <td>[advmod, punct, compound, nsubj, aux, root, ca...</td>\n",
       "      <td>[{'term': [',', 'hilary', 'swank'], 'from': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[my, 3-year-old, was, amazed, yesterday, to, f...</td>\n",
       "      <td>[PRP$, NN, VBD, VBN, NN, TO, VB, IN, '', JJ, '...</td>\n",
       "      <td>[2, 4, 4, 0, 4, 7, 4, 16, 10, 14, 14, 14, 14, ...</td>\n",
       "      <td>[nmod, nsubjpass, auxpass, root, nmod, mark, x...</td>\n",
       "      <td>[{'term': ['wii'], 'from': 21, 'to': 22, 'pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[God, damn, ,, That, Sony, remote, for, google...</td>\n",
       "      <td>[NNP, RB, ,, IN, NNP, JJ, IN, NN, VBZ, RB, JJ, .]</td>\n",
       "      <td>[0, 1, 1, 6, 6, 1, 8, 6, 10, 11, 1, 1]</td>\n",
       "      <td>[root, advmod, punct, mark, nsubj, amod, case,...</td>\n",
       "      <td>[{'term': ['google'], 'from': 7, 'to': 8, 'pol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               token  \\\n",
       "0  [i, agree, about, arafat, ,, i, mean, ,, shit,...   \n",
       "1  [musicmonday, britney, spears, -, lucky, do, y...   \n",
       "2  [wtf, ,, hilary, swank, is, coming, to, my, sc...   \n",
       "3  [my, 3-year-old, was, amazed, yesterday, to, f...   \n",
       "4  [God, damn, ,, That, Sony, remote, for, google...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [LS, VBP, IN, NN, ,, FW, NN, ,, NN, ,, PRP, RB...   \n",
       "1  [NN, NN, NNS, :, JJ, VBP, PRP, VB, DT, NN, ,, ...   \n",
       "2  [NN, ,, JJ, NN, VBZ, VBG, TO, PRP$, NN, NN, ,,...   \n",
       "3  [PRP$, NN, VBD, VBN, NN, TO, VB, IN, '', JJ, '...   \n",
       "4  [NNP, RB, ,, IN, NNP, JJ, IN, NN, VBZ, RB, JJ, .]   \n",
       "\n",
       "                                                head  \\\n",
       "0  [2, 0, 4, 2, 7, 7, 2, 7, 2, 2, 13, 13, 2, 13, ...   \n",
       "1  [3, 3, 0, 3, 3, 8, 8, 3, 10, 8, 8, 8, 8, 15, 3...   \n",
       "2  [6, 6, 4, 6, 6, 0, 9, 9, 6, 6, 6, 14, 14, 6, 1...   \n",
       "3  [2, 4, 4, 0, 4, 7, 4, 16, 10, 14, 14, 14, 14, ...   \n",
       "4             [0, 1, 1, 6, 6, 1, 8, 6, 10, 11, 1, 1]   \n",
       "\n",
       "                                              deprel  \\\n",
       "0  [nsubj, root, case, nmod, punct, nsubj, parata...   \n",
       "1  [amod, compound, root, punct, dep, aux, nsubj,...   \n",
       "2  [advmod, punct, compound, nsubj, aux, root, ca...   \n",
       "3  [nmod, nsubjpass, auxpass, root, nmod, mark, x...   \n",
       "4  [root, advmod, punct, mark, nsubj, amod, case,...   \n",
       "\n",
       "                                             aspects  \n",
       "0  [{'term': ['jimmy', 'carter'], 'from': 15, 'to...  \n",
       "1  [{'term': ['britney', 'spears'], 'from': 1, 't...  \n",
       "2  [{'term': [',', 'hilary', 'swank'], 'from': 1,...  \n",
       "3  [{'term': ['wii'], 'from': 21, 'to': 22, 'pola...  \n",
       "4  [{'term': ['google'], 'from': 7, 'to': 8, 'pol...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_json(\"tweets_data.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i agree about arafat , i mean , shit , they ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musicmonday britney spears - lucky do you reme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wtf , hilary swank is coming to my school toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my 3-year-old was amazed yesterday to find tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>God damn , That Sony remote for google is fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>really , that seems like more of a britney spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>the biggest loser wii review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>ok love game is on , , lady gaga , my dear , y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>nic cage sues business manager for ' financial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>the top 5 stars in need of help , , , asap : a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6051 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets\n",
       "0     i agree about arafat , i mean , shit , they ev...\n",
       "1     musicmonday britney spears - lucky do you reme...\n",
       "2     wtf , hilary swank is coming to my school toda...\n",
       "3     my 3-year-old was amazed yesterday to find tha...\n",
       "4     God damn , That Sony remote for google is fuck...\n",
       "...                                                 ...\n",
       "6046  really , that seems like more of a britney spe...\n",
       "6047                       the biggest loser wii review\n",
       "6048  ok love game is on , , lady gaga , my dear , y...\n",
       "6049  nic cage sues business manager for ' financial...\n",
       "6050  the top 5 stars in need of help , , , asap : a...\n",
       "\n",
       "[6051 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame(columns=['tweets'])\n",
    "X['tweets']=data['token']\n",
    "X['tweets']=X['tweets'].apply(lambda x:' '.join(x))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(columns=['polarity'])\n",
    "for i in data['aspects']:\n",
    "    for j in i:\n",
    "        y=y._append({'polarity':j['polarity']},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       negative\n",
       "1       positive\n",
       "2        neutral\n",
       "3        neutral\n",
       "4       negative\n",
       "          ...   \n",
       "6046     neutral\n",
       "6047    negative\n",
       "6048    positive\n",
       "6049     neutral\n",
       "6050     neutral\n",
       "Name: polarity, Length: 6051, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe=OneHotEncoder(drop='first')\n",
    "y_new=ohe.fit_transform(y[['polarity']]).toarray()\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6051, 1) (6051, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,SimpleRNN,Embedding\n",
    "from keras.utils import pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X['tweets']\n",
    "y=y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4538,) (4538, 2)\n",
      "(1513,) (1513, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=999,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok=tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tok=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[302, 264, 82, 776, 24, 185, 280, 469, 3, 1, 111, 2, 527, 5, 90, 564]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332       katy perry wants to crash the royal wedding , .\n",
       "833     when you compare lindsay lohan pre and post co...\n",
       "2582    Wave An Amazing list of all the google product...\n",
       "5709    industry games - guitar hero brand respected l...\n",
       "2611    the wii sucks , its fun for a couple of weeks ...\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[274, 278, 391, 3, 2, 852]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad=pad_sequences(X_train_tok)\n",
    "X_test_pad=pad_sequences(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 274, 278, 391,   3,   2, 852])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 302, 264,  82, 776,  24, 185, 280, 469,   3,   1, 111,\n",
       "         2, 527,   5,  90, 564])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 2)           4000      \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 64)                4288      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,418\n",
      "Trainable params: 8,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(2000,2))\n",
    "model.add(SimpleRNN(64,return_sequences=False))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "142/142 [==============================] - 2s 10ms/step - loss: 0.4797 - accuracy: 0.7488 - val_loss: 0.4824 - val_accuracy: 0.7568\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4790 - accuracy: 0.7490 - val_loss: 0.4782 - val_accuracy: 0.7568\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4795 - accuracy: 0.7490 - val_loss: 0.4770 - val_accuracy: 0.7568\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4797 - accuracy: 0.7490 - val_loss: 0.4758 - val_accuracy: 0.7568\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4799 - accuracy: 0.7490 - val_loss: 0.4826 - val_accuracy: 0.7568\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 0.4809 - accuracy: 0.7490 - val_loss: 0.4749 - val_accuracy: 0.7568\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4790 - accuracy: 0.7490 - val_loss: 0.4757 - val_accuracy: 0.7568\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4791 - accuracy: 0.7490 - val_loss: 0.4740 - val_accuracy: 0.7568\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4790 - accuracy: 0.7490 - val_loss: 0.4772 - val_accuracy: 0.7568\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 0.4804 - accuracy: 0.7490 - val_loss: 0.4754 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216556e3d90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad,y_train,epochs=10,validation_data=[X_test_pad,y_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflowenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
