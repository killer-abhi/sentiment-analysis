{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, agree, about, arafat, ,, i, mean, ,, shit,...</td>\n",
       "      <td>[LS, VBP, IN, NN, ,, FW, NN, ,, NN, ,, PRP, RB...</td>\n",
       "      <td>[2, 0, 4, 2, 7, 7, 2, 7, 2, 2, 13, 13, 2, 13, ...</td>\n",
       "      <td>[nsubj, root, case, nmod, punct, nsubj, parata...</td>\n",
       "      <td>[{'term': ['jimmy', 'carter'], 'from': 15, 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[musicmonday, britney, spears, -, lucky, do, y...</td>\n",
       "      <td>[NN, NN, NNS, :, JJ, VBP, PRP, VB, DT, NN, ,, ...</td>\n",
       "      <td>[3, 3, 0, 3, 3, 8, 8, 3, 10, 8, 8, 8, 8, 15, 3...</td>\n",
       "      <td>[amod, compound, root, punct, dep, aux, nsubj,...</td>\n",
       "      <td>[{'term': ['britney', 'spears'], 'from': 1, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wtf, ,, hilary, swank, is, coming, to, my, sc...</td>\n",
       "      <td>[NN, ,, JJ, NN, VBZ, VBG, TO, PRP$, NN, NN, ,,...</td>\n",
       "      <td>[6, 6, 4, 6, 6, 0, 9, 9, 6, 6, 6, 14, 14, 6, 1...</td>\n",
       "      <td>[advmod, punct, compound, nsubj, aux, root, ca...</td>\n",
       "      <td>[{'term': [',', 'hilary', 'swank'], 'from': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[my, 3-year-old, was, amazed, yesterday, to, f...</td>\n",
       "      <td>[PRP$, NN, VBD, VBN, NN, TO, VB, IN, '', JJ, '...</td>\n",
       "      <td>[2, 4, 4, 0, 4, 7, 4, 16, 10, 14, 14, 14, 14, ...</td>\n",
       "      <td>[nmod, nsubjpass, auxpass, root, nmod, mark, x...</td>\n",
       "      <td>[{'term': ['wii'], 'from': 21, 'to': 22, 'pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[God, damn, ,, That, Sony, remote, for, google...</td>\n",
       "      <td>[NNP, RB, ,, IN, NNP, JJ, IN, NN, VBZ, RB, JJ, .]</td>\n",
       "      <td>[0, 1, 1, 6, 6, 1, 8, 6, 10, 11, 1, 1]</td>\n",
       "      <td>[root, advmod, punct, mark, nsubj, amod, case,...</td>\n",
       "      <td>[{'term': ['google'], 'from': 7, 'to': 8, 'pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>[really, ,, that, seems, like, more, of, a, br...</td>\n",
       "      <td>[RB, ,, IN, VBZ, IN, JJR, IN, DT, NN, VBZ, NN,...</td>\n",
       "      <td>[4, 4, 4, 0, 6, 4, 11, 11, 11, 11, 6, 13, 11, ...</td>\n",
       "      <td>[advmod, punct, nsubj, root, case, nmod, case,...</td>\n",
       "      <td>[{'term': ['britney', 'spears'], 'from': 8, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>[the, biggest, loser, wii, review]</td>\n",
       "      <td>[DT, JJS, NN, NN, NN]</td>\n",
       "      <td>[5, 5, 5, 5, 0]</td>\n",
       "      <td>[det, amod, amod, compound, root]</td>\n",
       "      <td>[{'term': ['wii'], 'from': 3, 'to': 4, 'polari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>[ok, love, game, is, on, ,, ,, lady, gaga, ,, ...</td>\n",
       "      <td>[NN, NN, NN, VBZ, IN, ,, ,, NN, NNS, ,, PRP$, ...</td>\n",
       "      <td>[3, 3, 15, 15, 9, 9, 9, 9, 15, 9, 12, 9, 9, 15...</td>\n",
       "      <td>[amod, compound, nsubj, cop, case, punct, punc...</td>\n",
       "      <td>[{'term': [',', ',', 'lady', 'gaga'], 'from': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>[nic, cage, sues, business, manager, for, ', f...</td>\n",
       "      <td>[JJ, NN, VBZ, NN, NN, IN, '', JJ, VB, '', :, V...</td>\n",
       "      <td>[2, 3, 0, 5, 3, 9, 9, 9, 3, 9, 9, 9, 12, 18, 1...</td>\n",
       "      <td>[compound, nsubj, root, compound, dobj, case, ...</td>\n",
       "      <td>[{'term': ['nicolas', 'cage'], 'from': 16, 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>[the, top, 5, stars, in, need, of, help, ,, ,,...</td>\n",
       "      <td>[DT, JJ, CD, NNS, IN, NN, IN, NN, ,, ,, ,, NN,...</td>\n",
       "      <td>[4, 4, 4, 0, 6, 4, 8, 6, 4, 12, 12, 4, 12, 15,...</td>\n",
       "      <td>[det, amod, nummod, root, case, nmod, case, nm...</td>\n",
       "      <td>[{'term': ['lindsay', 'lohan'], 'from': 16, 't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6051 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  token  \\\n",
       "0     [i, agree, about, arafat, ,, i, mean, ,, shit,...   \n",
       "1     [musicmonday, britney, spears, -, lucky, do, y...   \n",
       "2     [wtf, ,, hilary, swank, is, coming, to, my, sc...   \n",
       "3     [my, 3-year-old, was, amazed, yesterday, to, f...   \n",
       "4     [God, damn, ,, That, Sony, remote, for, google...   \n",
       "...                                                 ...   \n",
       "6046  [really, ,, that, seems, like, more, of, a, br...   \n",
       "6047                 [the, biggest, loser, wii, review]   \n",
       "6048  [ok, love, game, is, on, ,, ,, lady, gaga, ,, ...   \n",
       "6049  [nic, cage, sues, business, manager, for, ', f...   \n",
       "6050  [the, top, 5, stars, in, need, of, help, ,, ,,...   \n",
       "\n",
       "                                                    pos  \\\n",
       "0     [LS, VBP, IN, NN, ,, FW, NN, ,, NN, ,, PRP, RB...   \n",
       "1     [NN, NN, NNS, :, JJ, VBP, PRP, VB, DT, NN, ,, ...   \n",
       "2     [NN, ,, JJ, NN, VBZ, VBG, TO, PRP$, NN, NN, ,,...   \n",
       "3     [PRP$, NN, VBD, VBN, NN, TO, VB, IN, '', JJ, '...   \n",
       "4     [NNP, RB, ,, IN, NNP, JJ, IN, NN, VBZ, RB, JJ, .]   \n",
       "...                                                 ...   \n",
       "6046  [RB, ,, IN, VBZ, IN, JJR, IN, DT, NN, VBZ, NN,...   \n",
       "6047                              [DT, JJS, NN, NN, NN]   \n",
       "6048  [NN, NN, NN, VBZ, IN, ,, ,, NN, NNS, ,, PRP$, ...   \n",
       "6049  [JJ, NN, VBZ, NN, NN, IN, '', JJ, VB, '', :, V...   \n",
       "6050  [DT, JJ, CD, NNS, IN, NN, IN, NN, ,, ,, ,, NN,...   \n",
       "\n",
       "                                                   head  \\\n",
       "0     [2, 0, 4, 2, 7, 7, 2, 7, 2, 2, 13, 13, 2, 13, ...   \n",
       "1     [3, 3, 0, 3, 3, 8, 8, 3, 10, 8, 8, 8, 8, 15, 3...   \n",
       "2     [6, 6, 4, 6, 6, 0, 9, 9, 6, 6, 6, 14, 14, 6, 1...   \n",
       "3     [2, 4, 4, 0, 4, 7, 4, 16, 10, 14, 14, 14, 14, ...   \n",
       "4                [0, 1, 1, 6, 6, 1, 8, 6, 10, 11, 1, 1]   \n",
       "...                                                 ...   \n",
       "6046  [4, 4, 4, 0, 6, 4, 11, 11, 11, 11, 6, 13, 11, ...   \n",
       "6047                                    [5, 5, 5, 5, 0]   \n",
       "6048  [3, 3, 15, 15, 9, 9, 9, 9, 15, 9, 12, 9, 9, 15...   \n",
       "6049  [2, 3, 0, 5, 3, 9, 9, 9, 3, 9, 9, 9, 12, 18, 1...   \n",
       "6050  [4, 4, 4, 0, 6, 4, 8, 6, 4, 12, 12, 4, 12, 15,...   \n",
       "\n",
       "                                                 deprel  \\\n",
       "0     [nsubj, root, case, nmod, punct, nsubj, parata...   \n",
       "1     [amod, compound, root, punct, dep, aux, nsubj,...   \n",
       "2     [advmod, punct, compound, nsubj, aux, root, ca...   \n",
       "3     [nmod, nsubjpass, auxpass, root, nmod, mark, x...   \n",
       "4     [root, advmod, punct, mark, nsubj, amod, case,...   \n",
       "...                                                 ...   \n",
       "6046  [advmod, punct, nsubj, root, case, nmod, case,...   \n",
       "6047                  [det, amod, amod, compound, root]   \n",
       "6048  [amod, compound, nsubj, cop, case, punct, punc...   \n",
       "6049  [compound, nsubj, root, compound, dobj, case, ...   \n",
       "6050  [det, amod, nummod, root, case, nmod, case, nm...   \n",
       "\n",
       "                                                aspects  \n",
       "0     [{'term': ['jimmy', 'carter'], 'from': 15, 'to...  \n",
       "1     [{'term': ['britney', 'spears'], 'from': 1, 't...  \n",
       "2     [{'term': [',', 'hilary', 'swank'], 'from': 1,...  \n",
       "3     [{'term': ['wii'], 'from': 21, 'to': 22, 'pola...  \n",
       "4     [{'term': ['google'], 'from': 7, 'to': 8, 'pol...  \n",
       "...                                                 ...  \n",
       "6046  [{'term': ['britney', 'spears'], 'from': 8, 't...  \n",
       "6047  [{'term': ['wii'], 'from': 3, 'to': 4, 'polari...  \n",
       "6048  [{'term': [',', ',', 'lady', 'gaga'], 'from': ...  \n",
       "6049  [{'term': ['nicolas', 'cage'], 'from': 16, 'to...  \n",
       "6050  [{'term': ['lindsay', 'lohan'], 'from': 16, 't...  \n",
       "\n",
       "[6051 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_json(\"tweets_data.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>aspects</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, agree, about, arafat, ,, i, mean, ,, shit,...</td>\n",
       "      <td>[LS, VBP, IN, NN, ,, FW, NN, ,, NN, ,, PRP, RB...</td>\n",
       "      <td>[2, 0, 4, 2, 7, 7, 2, 7, 2, 2, 13, 13, 2, 13, ...</td>\n",
       "      <td>[nsubj, root, case, nmod, punct, nsubj, parata...</td>\n",
       "      <td>[{'term': ['jimmy', 'carter'], 'from': 15, 'to...</td>\n",
       "      <td>i agree about arafat , i mean , shit , they ev...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[musicmonday, britney, spears, -, lucky, do, y...</td>\n",
       "      <td>[NN, NN, NNS, :, JJ, VBP, PRP, VB, DT, NN, ,, ...</td>\n",
       "      <td>[3, 3, 0, 3, 3, 8, 8, 3, 10, 8, 8, 8, 8, 15, 3...</td>\n",
       "      <td>[amod, compound, root, punct, dep, aux, nsubj,...</td>\n",
       "      <td>[{'term': ['britney', 'spears'], 'from': 1, 't...</td>\n",
       "      <td>musicmonday britney spears - lucky do you reme...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wtf, ,, hilary, swank, is, coming, to, my, sc...</td>\n",
       "      <td>[NN, ,, JJ, NN, VBZ, VBG, TO, PRP$, NN, NN, ,,...</td>\n",
       "      <td>[6, 6, 4, 6, 6, 0, 9, 9, 6, 6, 6, 14, 14, 6, 1...</td>\n",
       "      <td>[advmod, punct, compound, nsubj, aux, root, ca...</td>\n",
       "      <td>[{'term': [',', 'hilary', 'swank'], 'from': 1,...</td>\n",
       "      <td>wtf , hilary swank is coming to my school toda...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[my, 3-year-old, was, amazed, yesterday, to, f...</td>\n",
       "      <td>[PRP$, NN, VBD, VBN, NN, TO, VB, IN, '', JJ, '...</td>\n",
       "      <td>[2, 4, 4, 0, 4, 7, 4, 16, 10, 14, 14, 14, 14, ...</td>\n",
       "      <td>[nmod, nsubjpass, auxpass, root, nmod, mark, x...</td>\n",
       "      <td>[{'term': ['wii'], 'from': 21, 'to': 22, 'pola...</td>\n",
       "      <td>my 3-year-old was amazed yesterday to find tha...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[God, damn, ,, That, Sony, remote, for, google...</td>\n",
       "      <td>[NNP, RB, ,, IN, NNP, JJ, IN, NN, VBZ, RB, JJ, .]</td>\n",
       "      <td>[0, 1, 1, 6, 6, 1, 8, 6, 10, 11, 1, 1]</td>\n",
       "      <td>[root, advmod, punct, mark, nsubj, amod, case,...</td>\n",
       "      <td>[{'term': ['google'], 'from': 7, 'to': 8, 'pol...</td>\n",
       "      <td>God damn , That Sony remote for google is fuck...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>[really, ,, that, seems, like, more, of, a, br...</td>\n",
       "      <td>[RB, ,, IN, VBZ, IN, JJR, IN, DT, NN, VBZ, NN,...</td>\n",
       "      <td>[4, 4, 4, 0, 6, 4, 11, 11, 11, 11, 6, 13, 11, ...</td>\n",
       "      <td>[advmod, punct, nsubj, root, case, nmod, case,...</td>\n",
       "      <td>[{'term': ['britney', 'spears'], 'from': 8, 't...</td>\n",
       "      <td>really , that seems like more of a britney spe...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>[the, biggest, loser, wii, review]</td>\n",
       "      <td>[DT, JJS, NN, NN, NN]</td>\n",
       "      <td>[5, 5, 5, 5, 0]</td>\n",
       "      <td>[det, amod, amod, compound, root]</td>\n",
       "      <td>[{'term': ['wii'], 'from': 3, 'to': 4, 'polari...</td>\n",
       "      <td>the biggest loser wii review</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>[ok, love, game, is, on, ,, ,, lady, gaga, ,, ...</td>\n",
       "      <td>[NN, NN, NN, VBZ, IN, ,, ,, NN, NNS, ,, PRP$, ...</td>\n",
       "      <td>[3, 3, 15, 15, 9, 9, 9, 9, 15, 9, 12, 9, 9, 15...</td>\n",
       "      <td>[amod, compound, nsubj, cop, case, punct, punc...</td>\n",
       "      <td>[{'term': [',', ',', 'lady', 'gaga'], 'from': ...</td>\n",
       "      <td>ok love game is on , , lady gaga , my dear , y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>[nic, cage, sues, business, manager, for, ', f...</td>\n",
       "      <td>[JJ, NN, VBZ, NN, NN, IN, '', JJ, VB, '', :, V...</td>\n",
       "      <td>[2, 3, 0, 5, 3, 9, 9, 9, 3, 9, 9, 9, 12, 18, 1...</td>\n",
       "      <td>[compound, nsubj, root, compound, dobj, case, ...</td>\n",
       "      <td>[{'term': ['nicolas', 'cage'], 'from': 16, 'to...</td>\n",
       "      <td>nic cage sues business manager for ' financial...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>[the, top, 5, stars, in, need, of, help, ,, ,,...</td>\n",
       "      <td>[DT, JJ, CD, NNS, IN, NN, IN, NN, ,, ,, ,, NN,...</td>\n",
       "      <td>[4, 4, 4, 0, 6, 4, 8, 6, 4, 12, 12, 4, 12, 15,...</td>\n",
       "      <td>[det, amod, nummod, root, case, nmod, case, nm...</td>\n",
       "      <td>[{'term': ['lindsay', 'lohan'], 'from': 16, 't...</td>\n",
       "      <td>the top 5 stars in need of help , , , asap : a...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6051 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  token  \\\n",
       "0     [i, agree, about, arafat, ,, i, mean, ,, shit,...   \n",
       "1     [musicmonday, britney, spears, -, lucky, do, y...   \n",
       "2     [wtf, ,, hilary, swank, is, coming, to, my, sc...   \n",
       "3     [my, 3-year-old, was, amazed, yesterday, to, f...   \n",
       "4     [God, damn, ,, That, Sony, remote, for, google...   \n",
       "...                                                 ...   \n",
       "6046  [really, ,, that, seems, like, more, of, a, br...   \n",
       "6047                 [the, biggest, loser, wii, review]   \n",
       "6048  [ok, love, game, is, on, ,, ,, lady, gaga, ,, ...   \n",
       "6049  [nic, cage, sues, business, manager, for, ', f...   \n",
       "6050  [the, top, 5, stars, in, need, of, help, ,, ,,...   \n",
       "\n",
       "                                                    pos  \\\n",
       "0     [LS, VBP, IN, NN, ,, FW, NN, ,, NN, ,, PRP, RB...   \n",
       "1     [NN, NN, NNS, :, JJ, VBP, PRP, VB, DT, NN, ,, ...   \n",
       "2     [NN, ,, JJ, NN, VBZ, VBG, TO, PRP$, NN, NN, ,,...   \n",
       "3     [PRP$, NN, VBD, VBN, NN, TO, VB, IN, '', JJ, '...   \n",
       "4     [NNP, RB, ,, IN, NNP, JJ, IN, NN, VBZ, RB, JJ, .]   \n",
       "...                                                 ...   \n",
       "6046  [RB, ,, IN, VBZ, IN, JJR, IN, DT, NN, VBZ, NN,...   \n",
       "6047                              [DT, JJS, NN, NN, NN]   \n",
       "6048  [NN, NN, NN, VBZ, IN, ,, ,, NN, NNS, ,, PRP$, ...   \n",
       "6049  [JJ, NN, VBZ, NN, NN, IN, '', JJ, VB, '', :, V...   \n",
       "6050  [DT, JJ, CD, NNS, IN, NN, IN, NN, ,, ,, ,, NN,...   \n",
       "\n",
       "                                                   head  \\\n",
       "0     [2, 0, 4, 2, 7, 7, 2, 7, 2, 2, 13, 13, 2, 13, ...   \n",
       "1     [3, 3, 0, 3, 3, 8, 8, 3, 10, 8, 8, 8, 8, 15, 3...   \n",
       "2     [6, 6, 4, 6, 6, 0, 9, 9, 6, 6, 6, 14, 14, 6, 1...   \n",
       "3     [2, 4, 4, 0, 4, 7, 4, 16, 10, 14, 14, 14, 14, ...   \n",
       "4                [0, 1, 1, 6, 6, 1, 8, 6, 10, 11, 1, 1]   \n",
       "...                                                 ...   \n",
       "6046  [4, 4, 4, 0, 6, 4, 11, 11, 11, 11, 6, 13, 11, ...   \n",
       "6047                                    [5, 5, 5, 5, 0]   \n",
       "6048  [3, 3, 15, 15, 9, 9, 9, 9, 15, 9, 12, 9, 9, 15...   \n",
       "6049  [2, 3, 0, 5, 3, 9, 9, 9, 3, 9, 9, 9, 12, 18, 1...   \n",
       "6050  [4, 4, 4, 0, 6, 4, 8, 6, 4, 12, 12, 4, 12, 15,...   \n",
       "\n",
       "                                                 deprel  \\\n",
       "0     [nsubj, root, case, nmod, punct, nsubj, parata...   \n",
       "1     [amod, compound, root, punct, dep, aux, nsubj,...   \n",
       "2     [advmod, punct, compound, nsubj, aux, root, ca...   \n",
       "3     [nmod, nsubjpass, auxpass, root, nmod, mark, x...   \n",
       "4     [root, advmod, punct, mark, nsubj, amod, case,...   \n",
       "...                                                 ...   \n",
       "6046  [advmod, punct, nsubj, root, case, nmod, case,...   \n",
       "6047                  [det, amod, amod, compound, root]   \n",
       "6048  [amod, compound, nsubj, cop, case, punct, punc...   \n",
       "6049  [compound, nsubj, root, compound, dobj, case, ...   \n",
       "6050  [det, amod, nummod, root, case, nmod, case, nm...   \n",
       "\n",
       "                                                aspects  \\\n",
       "0     [{'term': ['jimmy', 'carter'], 'from': 15, 'to...   \n",
       "1     [{'term': ['britney', 'spears'], 'from': 1, 't...   \n",
       "2     [{'term': [',', 'hilary', 'swank'], 'from': 1,...   \n",
       "3     [{'term': ['wii'], 'from': 21, 'to': 22, 'pola...   \n",
       "4     [{'term': ['google'], 'from': 7, 'to': 8, 'pol...   \n",
       "...                                                 ...   \n",
       "6046  [{'term': ['britney', 'spears'], 'from': 8, 't...   \n",
       "6047  [{'term': ['wii'], 'from': 3, 'to': 4, 'polari...   \n",
       "6048  [{'term': [',', ',', 'lady', 'gaga'], 'from': ...   \n",
       "6049  [{'term': ['nicolas', 'cage'], 'from': 16, 'to...   \n",
       "6050  [{'term': ['lindsay', 'lohan'], 'from': 16, 't...   \n",
       "\n",
       "                                                   text     label  \n",
       "0     i agree about arafat , i mean , shit , they ev...  negative  \n",
       "1     musicmonday britney spears - lucky do you reme...  positive  \n",
       "2     wtf , hilary swank is coming to my school toda...   neutral  \n",
       "3     my 3-year-old was amazed yesterday to find tha...   neutral  \n",
       "4     God damn , That Sony remote for google is fuck...  negative  \n",
       "...                                                 ...       ...  \n",
       "6046  really , that seems like more of a britney spe...   neutral  \n",
       "6047                       the biggest loser wii review  negative  \n",
       "6048  ok love game is on , , lady gaga , my dear , y...  positive  \n",
       "6049  nic cage sues business manager for ' financial...   neutral  \n",
       "6050  the top 5 stars in need of help , , , asap : a...   neutral  \n",
       "\n",
       "[6051 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['token'].apply(lambda x: ' '.join(x))\n",
    "df['label'] = df['aspects'].apply(lambda x: x[0]['polarity'] if x else 'neutral')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(len(x) for x in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6051, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6051,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['encoded_label']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(SimpleRNN(35, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 35, 128)           1539200   \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 35)                5740      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 35)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                2304      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,547,439\n",
      "Trainable params: 1,547,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "190/190 [==============================] - 5s 22ms/step - loss: 1.0590 - accuracy: 0.4728\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.9186 - accuracy: 0.5698\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.5580 - accuracy: 0.7900\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.2289 - accuracy: 0.9248\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.1101 - accuracy: 0.9631\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.0775 - accuracy: 0.9754\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.0518 - accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.0388 - accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.0327 - accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 4s 22ms/step - loss: 0.0354 - accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Test accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n",
      "Text: I love this product --> Sentiment: positive\n",
      "Text: very bad product --> Sentiment: negative\n",
      "Text: It's okay, not bad --> Sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\"I love this product\", \"very bad product\", \"It's okay, not bad\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
    "predictions = model.predict(new_padded)\n",
    "predicted_classes = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "for text, sentiment in zip(new_texts, predicted_classes):\n",
    "    print(f\"Text: {text} --> Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[shaquille, o'neal, to, miss, 3rd, straight, p...</td>\n",
       "      <td>[NN, NN, TO, VB, JJ, JJ, NN, NN, SYM, DT, ,, ,...</td>\n",
       "      <td>[2, 0, 4, 2, 8, 8, 8, 4, 10, 8, 10, 10, 10, 10...</td>\n",
       "      <td>[nsubj, root, mark, xcomp, compound, amod, com...</td>\n",
       "      <td>[{'term': ['shaquille', 'o'neal'], 'from': 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Dear, justin, ,, Gray, Hoodies, turned, into,...</td>\n",
       "      <td>[NNP, NNP, ,, NNP, NNP, VBD, IN, NNP, NNPS, ,,...</td>\n",
       "      <td>[2, 6, 2, 5, 2, 0, 9, 9, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[compound, nsubj, punct, compound, appos, root...</td>\n",
       "      <td>[{'term': ['justin'], 'from': 1, 'to': 2, 'pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[received, my, google, wave, account, today, ,...</td>\n",
       "      <td>[VBN, PRP$, NN, NN, NN, NN, ,, JJ, VBP, DT, VB...</td>\n",
       "      <td>[9, 5, 5, 5, 1, 1, 9, 9, 0, 11, 9, 9, 9, 16, 1...</td>\n",
       "      <td>[advcl, nmod, compound, compound, dobj, nmod, ...</td>\n",
       "      <td>[{'term': ['google', 'wave'], 'from': 2, 'to':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[epascarello, I, know, ,, Man, I, get, pissed,...</td>\n",
       "      <td>[NN, PRP, VBP, ,, NNP, PRP, VBP, VBN, WRB, PRP...</td>\n",
       "      <td>[3, 3, 8, 3, 8, 8, 8, 0, 11, 11, 8, 13, 11, 15...</td>\n",
       "      <td>[advmod, nsubj, advcl, punct, nsubjpass, nsubj...</td>\n",
       "      <td>[{'term': ['google'], 'from': 16, 'to': 17, 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Is, it, just, me, ,, or, does, john, boehner,...</td>\n",
       "      <td>[VBZ, PRP, RB, PRP, ,, CC, VBZ, NN, JJ, NN, IN...</td>\n",
       "      <td>[15, 1, 4, 1, 1, 1, 10, 9, 10, 15, 13, 13, 10,...</td>\n",
       "      <td>[aux, nsubj, advmod, nsubj, punct, cc, aux, co...</td>\n",
       "      <td>[{'term': ['john', 'boehner'], 'from': 7, 'to'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>[not, a, goddamn, thing, ,, you, got, me, list...</td>\n",
       "      <td>[RB, DT, JJ, NN, ,, PRP, VBD, PRP, VBG, TO, NN...</td>\n",
       "      <td>[4, 4, 4, 7, 7, 7, 0, 9, 7, 14, 14, 11, 11, 9,...</td>\n",
       "      <td>[neg, det, amod, ccomp, punct, nsubj, root, ns...</td>\n",
       "      <td>[{'term': ['britney', 'spears'], 'from': 12, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>[barack, obama, made, the, bullies, stop, pick...</td>\n",
       "      <td>[NN, NN, VBD, DT, VBZ, VB, VBG, IN, PRP, .]</td>\n",
       "      <td>[2, 3, 0, 5, 6, 3, 6, 9, 7, 3]</td>\n",
       "      <td>[compound, nsubj, root, det, nsubj, ccomp, xco...</td>\n",
       "      <td>[{'term': ['barack', 'obama'], 'from': 0, 'to'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>[apple, has, better, windows, 7, support, than...</td>\n",
       "      <td>[NN, VBZ, JJR, NNS, CD, NN, IN, NN, VBZ, ,, CC...</td>\n",
       "      <td>[2, 0, 4, 2, 6, 2, 9, 9, 6, 2, 2, 14, 12, 15, ...</td>\n",
       "      <td>[nsubj, root, amod, dobj, nummod, dobj, mark, ...</td>\n",
       "      <td>[{'term': ['windows', '7'], 'from': 3, 'to': 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>[2, hours, later, ,, no, longer, seeing, confu...</td>\n",
       "      <td>[CD, NNS, RB, ,, DT, JJR, VBG, JJ, JJ, NN, NNS...</td>\n",
       "      <td>[2, 3, 8, 8, 6, 8, 8, 0, 11, 11, 8, 8]</td>\n",
       "      <td>[nummod, nmod, advmod, punct, neg, advmod, nsu...</td>\n",
       "      <td>[{'term': ['steve', 'jobs'], 'from': 9, 'to': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>['', Technically, if, a, girl, wants, to, spar...</td>\n",
       "      <td>['', NNP, IN, DT, NN, VBZ, TO, NN, PRP, MD, VB...</td>\n",
       "      <td>[11, 6, 6, 5, 6, 11, 8, 6, 11, 11, 0, 11, 11, ...</td>\n",
       "      <td>[punct, advmod, mark, det, nsubj, advcl, mark,...</td>\n",
       "      <td>[{'term': [',', '''', '-', 'demi', 'lovato'], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 token  \\\n",
       "0    [shaquille, o'neal, to, miss, 3rd, straight, p...   \n",
       "1    [Dear, justin, ,, Gray, Hoodies, turned, into,...   \n",
       "2    [received, my, google, wave, account, today, ,...   \n",
       "3    [epascarello, I, know, ,, Man, I, get, pissed,...   \n",
       "4    [Is, it, just, me, ,, or, does, john, boehner,...   \n",
       "..                                                 ...   \n",
       "672  [not, a, goddamn, thing, ,, you, got, me, list...   \n",
       "673  [barack, obama, made, the, bullies, stop, pick...   \n",
       "674  [apple, has, better, windows, 7, support, than...   \n",
       "675  [2, hours, later, ,, no, longer, seeing, confu...   \n",
       "676  ['', Technically, if, a, girl, wants, to, spar...   \n",
       "\n",
       "                                                   pos  \\\n",
       "0    [NN, NN, TO, VB, JJ, JJ, NN, NN, SYM, DT, ,, ,...   \n",
       "1    [NNP, NNP, ,, NNP, NNP, VBD, IN, NNP, NNPS, ,,...   \n",
       "2    [VBN, PRP$, NN, NN, NN, NN, ,, JJ, VBP, DT, VB...   \n",
       "3    [NN, PRP, VBP, ,, NNP, PRP, VBP, VBN, WRB, PRP...   \n",
       "4    [VBZ, PRP, RB, PRP, ,, CC, VBZ, NN, JJ, NN, IN...   \n",
       "..                                                 ...   \n",
       "672  [RB, DT, JJ, NN, ,, PRP, VBD, PRP, VBG, TO, NN...   \n",
       "673        [NN, NN, VBD, DT, VBZ, VB, VBG, IN, PRP, .]   \n",
       "674  [NN, VBZ, JJR, NNS, CD, NN, IN, NN, VBZ, ,, CC...   \n",
       "675  [CD, NNS, RB, ,, DT, JJR, VBG, JJ, JJ, NN, NNS...   \n",
       "676  ['', NNP, IN, DT, NN, VBZ, TO, NN, PRP, MD, VB...   \n",
       "\n",
       "                                                  head  \\\n",
       "0    [2, 0, 4, 2, 8, 8, 8, 4, 10, 8, 10, 10, 10, 10...   \n",
       "1    [2, 6, 2, 5, 2, 0, 9, 9, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "2    [9, 5, 5, 5, 1, 1, 9, 9, 0, 11, 9, 9, 9, 16, 1...   \n",
       "3    [3, 3, 8, 3, 8, 8, 8, 0, 11, 11, 8, 13, 11, 15...   \n",
       "4    [15, 1, 4, 1, 1, 1, 10, 9, 10, 15, 13, 13, 10,...   \n",
       "..                                                 ...   \n",
       "672  [4, 4, 4, 7, 7, 7, 0, 9, 7, 14, 14, 11, 11, 9,...   \n",
       "673                     [2, 3, 0, 5, 6, 3, 6, 9, 7, 3]   \n",
       "674  [2, 0, 4, 2, 6, 2, 9, 9, 6, 2, 2, 14, 12, 15, ...   \n",
       "675             [2, 3, 8, 8, 6, 8, 8, 0, 11, 11, 8, 8]   \n",
       "676  [11, 6, 6, 5, 6, 11, 8, 6, 11, 11, 0, 11, 11, ...   \n",
       "\n",
       "                                                deprel  \\\n",
       "0    [nsubj, root, mark, xcomp, compound, amod, com...   \n",
       "1    [compound, nsubj, punct, compound, appos, root...   \n",
       "2    [advcl, nmod, compound, compound, dobj, nmod, ...   \n",
       "3    [advmod, nsubj, advcl, punct, nsubjpass, nsubj...   \n",
       "4    [aux, nsubj, advmod, nsubj, punct, cc, aux, co...   \n",
       "..                                                 ...   \n",
       "672  [neg, det, amod, ccomp, punct, nsubj, root, ns...   \n",
       "673  [compound, nsubj, root, det, nsubj, ccomp, xco...   \n",
       "674  [nsubj, root, amod, dobj, nummod, dobj, mark, ...   \n",
       "675  [nummod, nmod, advmod, punct, neg, advmod, nsu...   \n",
       "676  [punct, advmod, mark, det, nsubj, advcl, mark,...   \n",
       "\n",
       "                                               aspects  \n",
       "0    [{'term': ['shaquille', 'o'neal'], 'from': 0, ...  \n",
       "1    [{'term': ['justin'], 'from': 1, 'to': 2, 'pol...  \n",
       "2    [{'term': ['google', 'wave'], 'from': 2, 'to':...  \n",
       "3    [{'term': ['google'], 'from': 16, 'to': 17, 'p...  \n",
       "4    [{'term': ['john', 'boehner'], 'from': 7, 'to'...  \n",
       "..                                                 ...  \n",
       "672  [{'term': ['britney', 'spears'], 'from': 12, '...  \n",
       "673  [{'term': ['barack', 'obama'], 'from': 0, 'to'...  \n",
       "674  [{'term': ['windows', '7'], 'from': 3, 'to': 5...  \n",
       "675  [{'term': ['steve', 'jobs'], 'from': 9, 'to': ...  \n",
       "676  [{'term': [',', '''', '-', 'demi', 'lovato'], ...  \n",
       "\n",
       "[677 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData=pd.read_json(\"test.json\")\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shaquille o'neal to miss 3rd straight playoff ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear justin , Gray Hoodies turned into Leather...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>received my google wave account today , sorry ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>epascarello I know , Man I get pissed when I t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it just me , or does john boehner sound lik...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>not a goddamn thing , you got me listening to ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>barack obama made the bullies stop picking on ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>apple has better windows 7 support than sony d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2 hours later , no longer seeing confused russ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>'' Technically if a girl wants to sparkle she ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "0    shaquille o'neal to miss 3rd straight playoff ...  negative\n",
       "1    Dear justin , Gray Hoodies turned into Leather...  positive\n",
       "2    received my google wave account today , sorry ...   neutral\n",
       "3    epascarello I know , Man I get pissed when I t...   neutral\n",
       "4    Is it just me , or does john boehner sound lik...  negative\n",
       "..                                                 ...       ...\n",
       "672  not a goddamn thing , you got me listening to ...   neutral\n",
       "673  barack obama made the bullies stop picking on ...  negative\n",
       "674  apple has better windows 7 support than sony d...  positive\n",
       "675  2 hours later , no longer seeing confused russ...   neutral\n",
       "676  '' Technically if a girl wants to sparkle she ...   neutral\n",
       "\n",
       "[677 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['text'] = testData['token'].apply(lambda x: ' '.join(x))\n",
    "testData['polarity'] = testData['aspects'].apply(lambda x: x[0]['polarity'] if x else 'neutral')\n",
    "testData.drop(columns=['deprel','pos','head','token','aspects'],inplace=True)\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences=tokenizer.texts_to_sequences(testData['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "test_padded = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "predictions = model.predict(test_padded)\n",
    "testData['predicted_classes'] = label_encoder.inverse_transform(np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    2\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "..  ..\n",
       "672  1\n",
       "673  0\n",
       "674  2\n",
       "675  1\n",
       "676  1\n",
       "\n",
       "[677 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=pd.DataFrame(label_encoder.fit_transform(testData['polarity']))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step - loss: 2.3862 - accuracy: 0.5406\n",
      "Test accuracy: 0.5406\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_padded, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>predicted_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shaquille o'neal to miss 3rd straight playoff ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear justin , Gray Hoodies turned into Leather...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>received my google wave account today , sorry ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>epascarello I know , Man I get pissed when I t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it just me , or does john boehner sound lik...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>not a goddamn thing , you got me listening to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>barack obama made the bullies stop picking on ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>apple has better windows 7 support than sony d...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2 hours later , no longer seeing confused russ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>'' Technically if a girl wants to sparkle she ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity  \\\n",
       "0    shaquille o'neal to miss 3rd straight playoff ...  negative   \n",
       "1    Dear justin , Gray Hoodies turned into Leather...  positive   \n",
       "2    received my google wave account today , sorry ...   neutral   \n",
       "3    epascarello I know , Man I get pissed when I t...   neutral   \n",
       "4    Is it just me , or does john boehner sound lik...  negative   \n",
       "..                                                 ...       ...   \n",
       "672  not a goddamn thing , you got me listening to ...   neutral   \n",
       "673  barack obama made the bullies stop picking on ...  negative   \n",
       "674  apple has better windows 7 support than sony d...  positive   \n",
       "675  2 hours later , no longer seeing confused russ...   neutral   \n",
       "676  '' Technically if a girl wants to sparkle she ...   neutral   \n",
       "\n",
       "    predicted_classes  \n",
       "0             neutral  \n",
       "1            positive  \n",
       "2            positive  \n",
       "3             neutral  \n",
       "4            negative  \n",
       "..                ...  \n",
       "672           neutral  \n",
       "673           neutral  \n",
       "674           neutral  \n",
       "675          negative  \n",
       "676          positive  \n",
       "\n",
       "[677 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "neutral     336\n",
       "positive    172\n",
       "negative    169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_classes\n",
       "neutral     308\n",
       "positive    209\n",
       "negative    160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['predicted_classes'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflowenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
